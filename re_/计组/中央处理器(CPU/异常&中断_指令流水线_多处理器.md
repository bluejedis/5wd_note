 <span style="color: silver;">

#  <span style="color: silver;"> <span style="color: Gold;">异常</span>和<span style="color: green;">中断</span>机制  

- 现代计算机的异常和中断处理系统
  - CPU数据通路
    - 异常检测逻辑
    - 异常响应逻辑
  - 外设接口
    - 中断请求逻辑
    - 中断控制逻辑
  - 操作系统
    - 中断服务程序
- 处理过程
  - 中断硬件电路和中断服务程序有机结合
  - 共同完成异常和中断的处理
<ul>

##  <span style="color: silver;">基本概念  

>pro： 异常事件的性质（2015）  
<ul>

###  <span style="color: silver;">定义
- 异常（内中断）
  - 由CPU内部产生的意外事件
- 中断（外中断）
  - 来自CPU外部的设备向CPU发出的中断请求
  - 通常用于信息的输入和输出
- 区别特点
  - 异常：CPU执行指令时内部检测到的同步事件
  - 中断：外部设备触发的异步事件

>pro：异常响应的时机（2023）  
###  <span style="color: Gold;">区别
1. 关联性
   - 异常：与特定指令相关
   - 中断：与指令无关
2. 检测方式
   - 异常：CPU自身完成
   - 中断：需通过中断请求线
  
###  <span style="color: silver;">~处理过程
- 触发条件
  - 执行第i条指令时检测到异常
  - 执行第i条指令后发现中断请求
- 处理流程
  - CPU打断当前程序
  - 转执行异常/中断处理程序
- 处理结果
  - 成功解决
    - 通过异常/中断返回指令
    - 回到第i条或i+1条指令继续执行
  - 致命错误
    - 终止用户程序
- 处理方式：通常 OS和driver完成
</ul>

##  <span style="color: GreenYellow;">分类  
<ul>

###  <span style="color: Gold;">异常 <span style="color: silver;">~  
- 硬故障中断
  - 硬连线异常引起
    - 存储器校验错
    - 总线错误
- 程序性异常（软件中断）
  - 执行指令引起的异常
    - 整除0
    - 溢出
    - 断点
    - 单步跟踪
    - 非法指令
    - 栈溢出
    - 地址越界
    - 缺页

#### 按发生原因和返回方式分类

##### （1）故障（Fault）  

>pro：异常或中断处理后指令重新执行的断点（2021）  

- 检测时机：指令启动后、执行结束前
- 常见故障
  - 非法操作码
  - 缺段/缺页
  - 除数为0
- 处理方式
  - 可恢复故障
    - 如缺段/缺页：调入所需段/页面后返回故障指令
  - 不可恢复故障
    - 如非法操作码/除数为0：终止进程执行

##### (2）自陷（Trap）  

>pro：自陷的原理和性质（2020）  

- 定义：预先安排的"异常"事件
- 实现方式
  - 特殊指令
  - 特殊控制标志
- 处理流程
  - 执行完自陷指令
  - 根据类型进行处理
  - 返回下一条指令（非转移指令）
  - 返回转移目标指令（转移指令）
- 应用实例
  - x86程序调试
  - 系统调用指令
  - 条件自陷指令

##### （3）终止（Abort）  
- 触发条件：无法继续执行的硬件故障
  - 控制器出错
  - 存储器校验错
  - 总线错误
- 特点
  - 非特定指令产生
  - 随机发生
- 处理方式：调出异常服务程序重启系统

### 中断的分类  

>pro：对中断和异常事件的判断（2009、2016、2020）  

#### 基本概念
- 定义：CPU外部、与指令无关的事件
- 来源
  - I/O设备中断
  - 特殊事件
- 处理机制
  - 通过中断请求信号线
  - 指令执行完后检查

#### 按可屏蔽性分类

##### （1）可屏蔽中断  
- 通过INTR请求线发出
- 可通过屏蔽字控制

##### （2）不可屏蔽中断  
- 通过NMI请求线发出
- 用于紧急硬件故障
- 不可被屏蔽



#### 其他分类方式
- 按识别服务程序地址方式
  - 向量中断
  - 非向量中断
- 按处理过程是否允许打断
  - 单重中断
  - 多重中断


</ul>

##   <span style="color: silver;">~<span style="color: Gold;">响应</span>过程  

###  <span style="color: silver;">概述
- CPU执行指令时的异常/中断处理
  - 当CPU检测到异常或中断请求时，需要进行处理
- 响应过程定义
  - 从检测到事件到调出处理程序的全过程
  - 称为异常和中断响应

###  <span style="color: silver;">详解

#### 1. 关中断  
- 在保存断点和程序状态期间，不能被新的中断打断
- 实现方式：
  - 通过设置"中断允许"（IF）触发器
  - IF=1：开中断，允许响应中断
  - IF=0：关中断，不允许响应中断

#### 2. 保存断点和程序状态  
- 断点（返回地址）保存
  - 送到栈或特定寄存器中
  - 通常保存在栈中以支持异常或中断的嵌套
- 程序状态保存
  - 被中断时的程序状态字寄存器PSW内容需保存
  - 保存位置：栈或特定寄存器
  - 目的：异常和中断返回时恢复到PSW中

#### 3. 识别异常和中断并转到相应的处理程序  
- 识别方式分类
  - 软件识别方式
    - CPU设置异常状态寄存器记录异常原因
    - 使用统一的异常或中断查询程序
    - 按优先级顺序查询异常状态寄存器
    - 检测异常和中断类型
  - 硬件识别方式（向量中断）
    - 中断向量：异常或中断处理程序的首地址
    - 中断向量表存放所有中断向量
    - 每个异常或中断指定一个中断类型号
    - 类型号和中断向量一一对应

###  <span style="color: Gold;">特点
- 整个响应过程是不可被打断的
- 处理流程：
  - 响应过程结束后，CPU从PC中取出对应中断服务程序的第一条指令开始执行
  - 执行直至中断返回
  - 由CPU通过执行中断服务程序完成
  - 整个中断处理过程是由软/硬件协同实现的
 
</ul>

# 指令流水线  

- 指令执行方式对比：
  - 单周期处理机：
    - 采用串行方法执行指令
    - 同一时刻CPU只执行一条指令
    - 功能部件使用率低
  - 现代计算机：
    - 采用指令流水线技术
    - 同一时刻多条指令在不同功能部件中并发执行
    - 优点：
      - 提高功能部件的并行性
      - 提高程序的执行效率
<ul>

## 基本概念

### 并行性提升方法
- 时间上的并行技术
  - 将任务分解为不同子阶段
  - 每个子阶段在不同功能部件上并行执行
  - 同一时刻可执行多个任务
  - 这种方法称为流水线技术
- 空间上的并行技术
  - 在处理机内设置多个执行相同任务的功能部件
  - 让这些功能部件并行工作
  - 这样的处理机称为超标量处理机

### 指令执行阶段
- 一条指令的执行过程可分解为若干阶段
- 每个阶段由相应的功能部件完成
- 将各阶段视为相应的流水段，构成指令流水线
- 5个基本阶段：
  - 取指（IF）：从指令存储器或Cache中取指令
  - 译码/读寄存器（ID）：操作控制器译码，从寄存器堆取操作数
  - 执行/计算地址（EX）：执行运算或计算地址
  - 访存（MEM）：对存储器进行读/写操作
  - 写回（WB）：将执行结果写回寄存器堆

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/4e4d3b2fd28bf010d15ebe5c04890299db4e9d522cfa5616dd58c870df156a3c.jpg)  

>pro：流水线对指令集的要求（2011）  

### 指令集要求
- 指令长度一致性
  - 应尽量保持一致
  - 有利于简化取指令和译码操作
  - 避免取指时间不一致导致部件复杂
- 指令格式规整性
  - 源寄存器位置应保持相同
  - 便于在指令未知时取寄存器操作数
- LOAD/STORE型指令设计
  - 其他指令不访问存储器
  - 有利于规整地址计算和运算步骤
- 存储对齐要求
  - 数据和指令需"按边界对齐"存放
  - 有利于减少访存次数

## 基本实现  

### 设计原则  
- 单周期实现特点
  - 不是所有指令都需要5个阶段
  - 时钟周期取决于最慢指令
  - 时钟频率受限于最长数据通路

>pro：流水线时钟周期的设计（2009）  

#### 流水线设计基本原则
- 流水段个数原则
  - 以最复杂指令所需功能段个数为准
- 流水段长度原则
  - 以最复杂操作所需时间为准
- 时间分析示例
  - 各阶段时间：
    - 取指：200ps
    - 译码：100ps
    - 执行：150ps
    - 访存：200ps
    - 写回：100ps
  - 执行效率比较：
    - 串行执行：N×750ps
    - 流水线执行：(N+4)×200ps

### 逻辑结构  
- 流水段寄存器设计
  - 每个流水段后增加流水段寄存器
  - 用于锁存本段处理完的数据
  - 确保结果可用于下一周期
- 时钟同步机制
  - 采用统一时钟CLK
  - 每个时钟周期：
    - 处理完的数据锁存到段寄存器
    - 接收前段传递的数据

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/15dad3e9b41ca386ed07524528163648ddba3b917ff3c224e8e9b044083935c5.jpg)  

>attention:  

在考试中，若没有明确说明，则可以不用考虑流水寄存器的时延。  

### 时空图表示  
- 时空图基本概念
  - 用于直观描述流水线执行情况
  - 横坐标：表示时间，分割为等长时间段T
  - 纵坐标：表示指令所处功能部件

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/8f92b2589c2fe4694603f3c9894919d540ed16f5065d6218d79024a19ab46846.jpg)  

>pro：流水线执行4条指令所需的时钟周期数（2012）  

#### 流水线性能分析
- 执行效率比较
  - 流水线方式：时刻10T有6条指令完成
  - 串行方式：时刻10T仅2条指令完成
- 适用场景
  - 适合连续任务执行
  - 特别适合指令执行
  - 浮点运算流水线仅适合运算密集型应用

## 冒险与处理  

>pro：导致流水线阻塞的各种原因（2010）  

在指令流水线中，可能会遇到一些情况使得后续指令无法正确执行而引起流水线阻塞，这利现象称为流水线冒险。根据导致冒险的原因不同分为结构冒险、数据冒险和控制冒险3种。  

不同类型指令在各流水段的操作是不同的，表5.2中列出了几类指令在各流水段中的操作。  
表5.2不同类型指令在各流水段中的操作
![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/0e6ae322ef1d230d3622eda619a0b7d751d40c5ad99cf6bbc3f88c1bdf5ad624.jpg)  

这几类指令将会在下面介绍流水线冲突时涉及。  

### 结构冒险  

>pro：解决结构冒险的办法（2016）  

- 定义：由不同指令在同一时刻争用同一功能部件而形成的冲突
  - 也称资源冲突
  - 由硬件资源竞争造成

- 示例：指令和数据存放在同一存储器引发的冲突
  - 第i条LOAD指令MEM段访存与第i+3条指令F段取指令同时发生
  - 解决方法：暂停后一条指令操作一个时钟周期

- 解决方案：
  1. 暂停策略
     - 前一指令访存时，暂停后续相关指令一个时钟周期
  2. 硬件冗余
     - 设置多个独立部件
     - 如：寄存器读写口独立
     - 如：数据存储器和指令存储器分离
     - 现代Cache采用数据Cache和指令Cache分离

### 数据冒险  

>pro：分析指令之间的数据冒险（2012、2014、2016、2019、2023）  

#### 基本概念
- 定义：后面指令用到前面指令的结果时，前面指令的结果还没有产生
- 主要类型：写后读（RAW）冲突
  - 发生在前面指令写结果之前，后面指令需要读取时

>attention:  

在按序执行的流水线中（统考中通常采用这种方式），只可能出现RAW冲突。

#### RAW冲突示例
- 指令序列：
  
  I1: add R1,R2,R3  #（R2）+（R3）→R1
  I2: sub R4,R1,R5  #（R1)-（R5）→R4
  
- 冲突原因：
  - I2的源操作数是I1的目的操作数
  - 流水线重叠导致读写顺序改变

表5.4add和sub指令发生先写后读（RAW）冲突
![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/416a1a3afa37aaf5df2546bab8ffd540b1a22415785989ec06871e8242ff2a92.jpg)  

#### 解决方案

##### 1. 延迟执行相关指令
- 实现方式：
  - 软件插入空操作"nop"指令
  - 硬件阻塞(stall)
- 优化方法：
  - 寄存器读写时间控制
    - 前半周期写入
    - 后半周期读出

表5.5用延迟相关指令的办法来解决RAW冲突
![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/83b58f5125520e327f2952f138d8b8e3e1c011a0b53539439425dabca2d3aec6.jpg)  

##### 2. 转发(旁路)技术
- 工作原理：
  - 设置相关转发通路
  - 直接使用中间数据
  - 避免等待写回寄存器

表5.6用转发技术来解决RAW冲突
![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/6e66822789ad2aac996fbfbdb4f43c39d585688d099743e0d47d9ac80812a914.jpg)  

##### 3. load-use数据冒险处理
- 问题特点：
  - load指令与紧邻运算指令存在数据相关
  - 无法通过转发技术解决
- 解决方法：
  - 编译器插入nop指令
  - 程序编译时优化指令顺序

表5.7用延迟加转发技术来解决load-use冲突
![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/d8f74604a1f7296c5efc84ccc1b539219931dc8dd2633e2e187d4d2cf904438d.jpg)  

### 控制冒险  

>pro：分析指令之间的控制冒险（2014、2023）  

#### 基本概念
- 定义：改变指令执行顺序导致的冲突
- 触发条件：
  - 执行转移指令
  - 执行返回指令
  - 发生中断或异常

#### 处理示例
- 延迟处理方法：
  - 推迟后续指令执行
  - 插入nop指令

表5.8用插入空操作的办法解决控制冲突
![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/5d0c7063bc5e9cb5cf392f3925551cca3ebbfb37ad2e468043801a4c994d2fcf.jpg)  

#### 解决方案
1. 基本方法
   - 软件插入"nop"指令
   - 硬件阻塞(stall)

2. 分支预测
   - 简单(静态)预测
     - 预设条件不满足时继续顺序执行
   - 动态预测
     - 基于历史情况动态调整
     - 具有较高预测准确率

>attention:  

Cache缺失的处理过程也会引起流水线阻塞。
## 性能指标  

### 流水线的吞吐率
#### 定义
- 流水线的吞吐率是指在单位时间内流水线所完成的任务数量，或输出结果的数量

>pro：  流水线吞吐率的计算（2013）  

#### 基本公式
- 流水线吞吐率（TP）的最基本公式为：
  $
  \mathrm{TP}\,{=}\,\frac{n}{T_{k}}
  $  
  - 式中：
    - $n$ 是任务数
    - $T_{k}$ 是处理完 $n$ 个任务所用的总时间

#### 理想情况计算
- 设定条件：
  - $k$ 为流水段的段数
  - $\Delta t$ 为时钟周期
- 计算过程：
  - 在输入流水线中的任务连续的理想情况下
  - 一条 $k$ 段流水线能在 $k+n-1$ 个时钟周期内完成 $n$ 个任务
  - 得出流水线的吞吐率为：
    $
    \mathrm{TP}=\frac{n}{(k+n-1)\Delta t}
    $  
- 最大吞吐率：
  - 当连续输入的任务数 $n{\rightarrow}\infty$ 时
  - $\mathrm{TP}_{\mathrm{max}}\,{=}1/\Delta t$  

### 流水线的加速比  
#### 定义
- 完成同样一批任务，不使用流水线与使用流水线所用的时间之比

#### 基本公式
- 流水线加速比（S）的基本公式为：
  $
  S=\frac{T_{0}}{T_{k}}
  $  
  - 式中：
    - $T_{0}$ 表示不使用流水线的总时间
    - $T_{k}$ 表示使用流水线的总时间

#### 计算过程
- 时间计算：
  - 一条 $k$ 段流水线完成 $n$ 个任务所需的时间：$T_{k}=\left(k+n-1\right)\Delta t$
  - 顺序执行 $n$ 个任务时，所需的总时间：$T_{0}={kn}\Delta t$
- 加速比计算：
  - 将 $T_{0}$ 和 $T_{k}$ 值代入得：
    $
    S=\frac{k n\Delta t}{(k+n-1)\Delta t}\!=\!\frac{k n}{k+n-1}
    $  
- 最大加速比：
  - 当连续输入的任务数 $n{\rightarrow}\infty$ 时
  - $S_{\mathrm{max}}\,{=}\,k,$  

## 高级流水线技术  

- 有两种增加指令级并行的策略：
  - 多发射技术：采用多个内部功能部件，使流水线功能段能同时处理多条指令
  - 超流水线技术：通过增加流水线级数来使更多的指令同时在流水线中重叠执行

### 多发射技术
#### 超标量流水线技术  

>pro：超标量流水线的特性(2017)  

- 也称动态多发射技术
- 特点：
  - 每个时钟周期内可并发多条独立指令
  - 以并行操作方式将两条或多条指令编译并执行
  - 需配置多个功能部件
- 执行方式：
  - 简单超标量CPU：指令按顺序发射执行
  - 多数超标量CPU：
    - 结合动态流水线调度技术
    - 通过动态分支预测等手段
    - 指令不按顺序执行（乱序执行）

#### 超长指令字技术  

- 也称静态多发射技术
- 特点：
  - 由编译程序挖掘出指令间潜在的并行性
  - 将多条能并行操作的指令组合成超长指令字
  - 指令字可达几百位
  - 需要采用多个处理部件

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/3fb915064ad6368ced430ed580e5bb36216c80da07ef16f0bb6a2923dd9be00f.jpg)  
图5.19超标量流水线技术  

### 超流水线技术  

- 原理：
  - 通过提高流水线主频来提升性能
  - 流水线功能段划分越多，时钟周期越短
  - 指令吞吐率越高
- 限制：
  - 流水线级数越多，用于流水寄存器的开销越大
  - 流水线级数有限制，不是越多越好

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/742aac8f955fdb4c6ca794363252545db1e5f37ff8e48bc846bf71986d0fa0d6.jpg)  
图5.20超流水线技术  

>pro：基本流水线CPU和超标量流水线CPU的CPI（2020）  

- 超流水线CPU：
  - 流水线充满后，每个时钟周期执行一条指令
  - CPI=1
  - 主频更高
- 多发射流水线CPU：
  - 每个时钟周期可以处理多条指令
  - CPI<1
  - 成本更高、控制更复杂
</ul>

#  <span style="color: silver;"><span style="color: RoyalBlue;">多</span>处理器

>pro： 多处理器的基本概念（2022）  
<ul>

## SISD、SIMD、MIMID的基本概念  

基于指令流的数量和数据流的数量，将计算机体系结构分为SISD、SIMD、MISD和MIMD四类。常规的单处理器属于SISD，而常规的多处理器属于MIMD。  

### 单指令流单数据流（SISD）结构  
- SISD是传统的事行计算机结构
  - 特点：
    - 仅包含一个处理器和一个存储器
    - 一段时间内仅执行一条指令
    - 按指令流规定的顺序串行执行指令流中的若干指令
  - 优化方式：
    - 采用流水线方式提高速度
    - 设置多个功能部件
    - 采用多模块交叉方式组织存储器

### 单指令流多数据流（SIMID）结构  
- SIMID定义：一个指令流同时对多个数据流进行处理
  - 也称为数据级并行技术
- 结构组成：
  - 一个指令控制部件
  - 多个处理单元
    - 每个单元执行相同指令
    - 拥有独立的地址寄存器
    - 处理不同的数据
- 应用效率：
  - 最高效：for循环处理数组
  - 最低效：case或switch语句

### 多指令流单数据流（MISD）结构  
- 定义：同时执行多条指令，处理同一个数据
- 实际上不存在这样的计算机

### 多指令流多数据流（MIIMID）结构  
- 定义：同时执行多条指令分别处理多个不同的数据
- 分类：
  #### 多计算机系统
  - 特点：
    - 每个节点具有私有存储器
    - 具有独立主存地址空间
    - 通过消息传递进行数据传送
    - 也称消息传递MIIMID
  
  #### 多处理器系统
  - 特点：
    - 共享存储多处理器(SMP)系统
    - 具有共享的单一地址空间
    - 通过存取指令访问所有存储器
    - 也称共享存储MIIMID

#### 向量处理器
- 定义：SIMID的变体，实现直接操作一维数组指令集的CPU
- 工作原理：
  - 将数据组按顺序放入向量寄存器
  - 以流水化方式依次操作
  - 结果写回寄存器
- 应用优势：
  - 特定工作环境中性能提升显著
  - 尤其在数值模拟等领域

#### 并行计算模式对比
- SIMD：数据级并行模式
- MIMD：线程级或更高级别的并行计算模式
## 硬件多线程的基本概念  

- 在传统CPU中，线程的切换包含一系列开销，频繁地切换会极大影响系统的性能
- 为了减少线程切换过程中的开销，便诞生了硬件多线程
  - 在支持硬件多线程的CPU中：
    - 必须为每个线程提供单独的通用寄存器组、单独的程序计数器等
    - 线程的切换只需激活选中的寄存器
    - 省略了与存储器数据交换的环节
    - 大大减少了线程切换的开销

### 硬件多线程的实现方式
#### 细粒度多线程  
- 多个线程之间轮流交叉执行指令
  - 多个线程之间的指令是不相关的，可以乱序并行执行
  - 处理器能在每个时钟周期切换线程
    - 例如：
      - 在时钟周期i，将线程A中的多条指令发射执行
      - 在时钟周期 $\mathrm{i}+1$ ，将线程B中的多条指令发射执行

#### 粗粒度多线程  
- 连续几个时钟周期都执行同一线程的指令序列
- 仅在当前线程出现了较大开销的阻塞时才切换线程，如Cache缺失
- 特点：
  - 当发生流水线阻塞时，必须清除被阻塞的流水线
  - 新线程的指令开始执行前需要重载流水线
  - 线程切换的开销比细粒度多线程更大

- 上述两种多线程技术：
  - 都实现了指令级并行
  - 但线程级不并行

#### 同时多线程  
- 同时多线程（SMT）是上述两种多线程技术的变体
  - 在实现指令级并行的同时，实现线程级并行
  - 在同一个时钟周期中，发射多个不同线程中的多条指令执行

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/fe12e3816bacd5ce1624427dc34539902f856a1a779a1dfcb27e86ac5ec6d5bd.jpg)  

- Intel处理器中的超线程（Hyper-threading）：
  - 就是同时多线程SMT
  - 在一个单处理器或单个核中设置了两套线程状态部件
  - 共享高速缓存和功能部件

## 多核处理器的基本概念  
- 定义：将多个处理单元集成到单个CPU中
  - 每个处理单元称为一个核（core）
  - 通常也称片上多处理器
- 特点：
  - 每个核既可以有自己的Cache，又可以共享同一个Cache
  - 所有核通常共享主存储器

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/4e190cda79c5d3789bba4003dd4e0cf2eedc2899411a4baf8ced7fc668357302.jpg)  
图5.22不共享Cache的双核CPU结构  

### 多核系统的性能发挥
- 必须采用多线程（或多进程）执行
  - 使得每个核在同一时刻都有线程在执行
- 与单核的区别：
  - 多核上的多个线程是在物理上并行执行的
    - 是真正意义上的并行执行
    - 在同一时刻有多个线程在并行执行
  - 单核上的多线程是一种多线程交错执行
    - 在同一时刻只有一个线程在执行

### 实例说明
- 假设要将四颗圆石头滚到马路对面：
  - 滚动每颗石头平均需花费1分钟
  - 不同处理方式：
    - 串行处理器：逐一滚动每颗石头，花费4分钟
    - 双核处理器：两个人各滚两颗，花费2分钟
    - 向量处理器：用木板同时推动四块石头，理论上1分钟
  - 对比：
    - 多核处理器相当于拥有多名工人
    - 向量处理器拥有同时对多件事进行相同操作的方法

## 共享内存多处理器的基本概念  
### 定义与特点
- 具有共享的单一物理地址空间的多处理器
- 通信方式：
  - 处理器通过存储器中的共享变量互相通信
  - 所有处理器都能通过存取指令访问存储器的任何位置
- 注意：即使共享同一个物理地址空间，仍然可在自己的虚拟地址空间中单独运行程序

### 类型划分
#### 统一存储访问（UMA）多处理器
- 特点：
  - 每个处理器对所有存储单元的访问时间大致相同
  - 访问时间与处理器和访问位置无关
- 架构特征：
  - 内存控制器未整合进CPU
  - 访存操作需经过北桥芯片
  - CPU通过前端总线和北桥芯片相连

#### 非统一存储访问（NUMA）多处理器
- 特点：
  - 存储器访存速度不同
  - 访问速度取决于处理器和访问位置
  - 主存被分割分配给不同处理器
- 架构优势：
  - 消除UMA架构的瓶颈
  - 内存控制器集成到CPU内部
  - 每个CPU有独立内存控制器和本地内存
  - CPU间通过QPI总线相连

### 共享变量访问控制
- 问题：多个处理器可能同时访问同一共享变量
- 解决方案：
  - 需要进行同步操作
  - 通过对共享变量加锁控制互斥访问
  - 一次只允许一个处理器获得锁
  - 其他处理器需等待解锁

### Cache一致性
- UMA构架多处理器中的一致性要求：
  - Cache与主存之间的数据一致性
  - 各CPU的Cache之间的一致性
  - 不同CPU的Cache对同一内存位置的数据应保持一致
</ul>

#   <span style="color: silver;">本章小结  

本章开头提出的问题的参考答案如下。  

1）指令和数据均存放在内存中，计算机如何从时间和空间上区分它们是指令还是数据？  

从时间上讲，取指令事件发生在“取指周期”，取数据事件发生在“执行周期”。从空间上讲，从内存读出的指令流流向控制器（指令寄存器），从内存读出的数据流流向运算器（通用寄存器）  

2）什么是指令周期、机器周期和时钟周期？它们之间有何关系？  

CPU每取出并执行一条指令所需的全部时间称为指令周期；机器周期是在同步控制的机器中，执行指令周期中一步相对完整的操作（指令步）所需的时间，通常安排机器周期长度 $=$ 主存周期；时钟周期是指计算机主时钟的周期时间，它是计算机运行时最基本的时序单位，对应完成一个微操作所需的时间，通常时钟周期 $=$ 计算机主频的倒数。  
3）什么是微指令？它和第4章谈到的指令有什么关系？  

控制部件通过控制线向执行部件发出各种控制命令，通常把这种控制命令称为微命令，而一组实现一定操作功能的微命令的组合，构成一条微指令。许多条微指令组成的序列构成微程序， 微程序完成对指令的解释执行。指令，即指机器指令。每条指令可以完成一个独立的算术运算或逻辑运算操作。在采用微程序控制器的CPU中，一条指令对应一个微程序，一个微程序由许多微指令构成，一条微指令会发出很多不同的微命令。  

4）什么是指令流水线？指令流水线相对于传统体系结构的优势是什么？  

指令流水线是把指令分解为若干子过程，通过将每个子过程与其他子过程并行执行，来提高计算机的吞吐率的技术。采用流水线技术只需增加少量硬件就能把计算机的运算速度提高几倍，因此成为计算机中普遍使用的一种并行处理技术，通过在同一个时间段使用各功能部件，使得利用率明显提高。  

#  <span style="color: silver;">常见问题和易混淆知识点  

1.流水线越多，并行度就越高。是否流水段越多，指令执行越快？  

错误，原因如下：  

1）流水段缓冲之间的额外开销增大。每个流水段有一些额外开销用于缓冲间传送数据、进行各种准备和发送等功能，这些开销加长了一条指令的整个执行时间，当指令间逻辑上相互依赖时，开销更大。  

2）流水段间控制逻辑变多、变复杂。用于流水线优化和存储器（或寄存器）冲突处理的控制逻辑将随流水段的增加而大增，这可能导致用于流水段之间控制的逻辑比段本身的控制逻辑更复杂。  

2.读后写（WAR）相关和写后写（WAW）相关的概念  

1）读后写（WriteAfterRead，WAR）冲突。表示当前指令读出数据后，下一条指令才能写该寄存器。否则，先写后读，读到的就是错误（新）数据。在下列指令中，寄存器R1可能存在这样的冲突，当指令12试图在指令Ⅱ1读R1之前就写入该寄存器时，指令I1就错误地读出该寄存器新的内容。  

I1 add R3,R1,R2  $\begin{array}{r l}{\#\left(\mathbb{R}{1}\right)+\left(\mathbb{R}{2}\right)\rightarrow\mathbb{R}{3}}&{{}}\\ {\#\left(\mathbb{R}{4}\right)-\left(\mathbb{R}{5}\right)\rightarrow\mathbb{R}{1}}&{{}}\end{array}$  I2 sub R1,R4,R5  

在读后写（WAR）冲突中，指令I2的目的操作数是指令I1的源操作数。  

3）写后写（WriteAfterWrite，WAW）相关。表示当前指令写入寄存器后，下一条指令才能写该寄存器。否则，下一条指令在当前指令之前写，将使寄存器的值不是最新值。在下列指令中，寄存器RI可能存在这样的冲突，当指令I2试图在指令I1之前就写入R1时，就会错误地使由指令11写入的值成为该寄存器的内容。  

I1 add R1,R2,R3  $\begin{array}{r}{\#\left(\mathbb{R}2\right)+\left(\mathbb{R}3\right)\rightarrow\mathbb{R}1}\\ {\#\left(\mathbb{R}4\right)-\left(\mathbb{R}5\right)\rightarrow\mathbb{R}1}\end{array}$  I2 sub R1,R4,R5  

在写后写（WAW）冲突中，指令I2和指令I1的目的操作数是相同的。  

>attention:  

在非按序执行的流水线中，因为允许后进入流水线的指令超过先进入流水线的指令而先流出流水线，所以既可能发生RAW相关，又可能发生WAR和WAW相关。 